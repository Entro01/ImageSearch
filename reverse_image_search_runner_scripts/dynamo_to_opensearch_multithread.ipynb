{
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 408,
          "sourceType": "datasetVersion",
          "datasetId": 180
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import pandas as pd\n",
        "import base64\n",
        "import json\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from typing import List, Dict, Optional\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "class ImageEmbeddingProcessor:\n",
        "    def __init__(self, region: str = \"us-east-1\", max_workers: int = 10, batch_size: int = 100):\n",
        "        self.region = region\n",
        "        self.max_workers = max_workers\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Initialize AWS clients\n",
        "        self.bedrock_client = boto3.client(\n",
        "            \"bedrock-runtime\",\n",
        "            region,\n",
        "            endpoint_url=f\"https://bedrock-runtime.{region}.amazonaws.com\"\n",
        "        )\n",
        "        self.dynamodb = boto3.resource('dynamodb', region_name=region)\n",
        "        self.table = self.dynamodb.Table('reverse_image_search')\n",
        "\n",
        "        # Setup batch writer\n",
        "        self.batch_writer = self.table.batch_writer()\n",
        "\n",
        "    def process_batch(self, batch_df: pd.DataFrame) -> None:\n",
        "        \"\"\"Process a batch of images using thread pool\"\"\"\n",
        "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            futures = []\n",
        "            for _, row in batch_df.iterrows():\n",
        "                future = executor.submit(self._process_single_image, row)\n",
        "                futures.append(future)\n",
        "\n",
        "            # Process completed futures with progress bar\n",
        "            for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing batch\"):\n",
        "                try:\n",
        "                    result = future.result()\n",
        "                    if result:\n",
        "                        self._store_embedding_batch(*result)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing image: {e}\")\n",
        "\n",
        "    def _process_single_image(self, row) -> Optional[tuple]:\n",
        "        \"\"\"Process a single image and return product_id and embedding\"\"\"\n",
        "        try:\n",
        "            modified_url = self._modify_image_url(row['image_one'])\n",
        "            image_data = self._download_image(modified_url)\n",
        "\n",
        "            if image_data is None:\n",
        "                return None\n",
        "\n",
        "            base64_encoded_image = base64.b64encode(image_data).decode('utf-8')\n",
        "            embedding = self._create_image_embedding(base64_encoded_image)\n",
        "\n",
        "            if embedding:\n",
        "                return (row['product_id'], embedding)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing product {row['product_id']}: {e}\")\n",
        "        return None\n",
        "\n",
        "    def _store_embedding_batch(self, product_id: int, embedding: List[float]) -> None:\n",
        "        \"\"\"Store embedding using batch writer\"\"\"\n",
        "        try:\n",
        "            self.batch_writer.put_item(\n",
        "                Item={\n",
        "                    'product_id': product_id,\n",
        "                    'image_embedding': json.dumps(embedding)\n",
        "                }\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error storing embedding for product {product_id}: {e}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _modify_image_url(original_url: str, resolution: str = '448x448') -> str:\n",
        "        parts = original_url.split('/')\n",
        "        try:\n",
        "            resolution_index = next(i for i, part in enumerate(parts) if 'x' in part)\n",
        "            parts[resolution_index] = resolution\n",
        "            return '/'.join(parts)\n",
        "        except StopIteration:\n",
        "            return original_url.replace('cloudfront.net/', f'cloudfront.net/{resolution}/')\n",
        "\n",
        "    @staticmethod\n",
        "    def _download_image(url: str) -> Optional[bytes]:\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            return response.content\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Error downloading image from {url}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _create_image_embedding(self, image: str) -> Optional[List[float]]:\n",
        "        try:\n",
        "            response = self.bedrock_client.invoke_model(\n",
        "                body=json.dumps({\"inputImage\": image}),\n",
        "                modelId=\"amazon.titan-embed-image-v1\",\n",
        "                accept=\"application/json\",\n",
        "                contentType=\"application/json\"\n",
        "            )\n",
        "\n",
        "            result = json.loads(response.get(\"body\").read())\n",
        "            if \"message\" in result:\n",
        "                print(f\"Error creating embeddings: {result['message']}\")\n",
        "                return None\n",
        "\n",
        "            return result.get(\"embedding\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating embedding: {e}\")\n",
        "            return None\n",
        "\n",
        "    def process_dataset(self, df: pd.DataFrame, start_product_id: Optional[int] = None) -> None:\n",
        "        \"\"\"\n",
        "        Process dataset in batches, optionally starting from a specific product_id\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): Input DataFrame\n",
        "            start_product_id (int, optional): Product ID to start processing from\n",
        "        \"\"\"\n",
        "        # Filter DataFrame if start_product_id is provided\n",
        "        if start_product_id is not None:\n",
        "            df = df[df['product_id'] > start_product_id].copy()\n",
        "            print(f\"Starting from product_id > {start_product_id}\")\n",
        "            print(f\"Remaining items to process: {len(df)}\")\n",
        "\n",
        "        if len(df) == 0:\n",
        "            print(\"No items to process\")\n",
        "            return\n",
        "\n",
        "        total_processed = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i in range(0, len(df), self.batch_size):\n",
        "            batch_df = df[i:i + self.batch_size]\n",
        "            self.process_batch(batch_df)\n",
        "            total_processed += len(batch_df)\n",
        "\n",
        "            # Print progress\n",
        "            elapsed_time = time.time() - start_time\n",
        "            rate = total_processed / elapsed_time\n",
        "            print(f\"\\nProgress: {total_processed}/{len(df)} images\")\n",
        "            print(f\"Processing rate: {rate:.2f} images/second\")\n",
        "            print(f\"Estimated time remaining: {(len(df) - total_processed) / rate / 60:.2f} minutes\")\n",
        "\n",
        "            # Optional: Save checkpoint\n",
        "            last_processed_id = batch_df['product_id'].max()\n",
        "            print(f\"Last processed product_id: {last_processed_id}\")\n",
        "\n",
        "# Usage example\n",
        "processor = ImageEmbeddingProcessor(max_workers=10, batch_size=100)\n",
        "df = pd.read_csv('sample_dataset.csv')\n",
        "df = df.drop_duplicates(subset='product_id', keep='first')\n",
        "\n",
        "# Start processing from a specific product_id\n",
        "last_processed_id = 500  # Replace with your last processed product_id\n",
        "processor.process_dataset(df, start_product_id=last_processed_id)"
      ],
      "metadata": {
        "id": "qFLR6qi8WM4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t0i90fkyW00q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
